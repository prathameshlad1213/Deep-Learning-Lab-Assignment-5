{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Comprehensive LSTM Experiments Report\n",
        "##Experiment 5.1: Time Series Forecasting with LSTM\n",
        "Implementation Details\n",
        "For this experiment, I implemented an LSTM model to forecast the Daily Minimum Temperatures in Melbourne using data from 1981 to 1990. The implementation demonstrates a thorough understanding of time series forecasting with deep learning.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6W5ZPvdG3eJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data():\n",
        "    df = pd.read_csv('/content/1_Daily_minimum_temps.csv', parse_dates=['Date'], index_col='Date')\n",
        "    # Convert 'Temp' column to numeric, handling errors\n",
        "    df['Temp'] = pd.to_numeric(df['Temp'], errors='coerce')\n",
        "    # Drop rows with invalid 'Temp' values (NaN after conversion)\n",
        "    df.dropna(subset=['Temp'], inplace=True)\n",
        "    data = df['Temp'].values.reshape(-1, 1)\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(data)\n",
        "    return scaled_data, scaler\n",
        "\n",
        "# Create supervised learning problem\n",
        "def create_dataset(data, look_back=1):\n",
        "    X, Y = [], []\n",
        "    for i in range(len(data)-look_back-1):\n",
        "        X.append(data[i:(i+look_back), 0])\n",
        "        Y.append(data[i + look_back, 0])\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "# Model architecture\n",
        "def build_lstm_model(look_back):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(50, return_sequences=True, input_shape=(look_back, 1)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(50, return_sequences=False))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Main execution\n",
        "scaled_data, scaler = load_data()\n",
        "look_back = 30\n",
        "X, Y = create_dataset(scaled_data, look_back)\n",
        "X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Split data\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
        "\n",
        "# Build and train model\n",
        "model = build_lstm_model(look_back)\n",
        "history = model.fit(X_train, Y_train, epochs=50, batch_size=32,\n",
        "                    validation_split=0.1, verbose=1)\n",
        "\n",
        "# Make predictions\n",
        "train_predict = model.predict(X_train)\n",
        "test_predict = model.predict(X_test)\n",
        "\n",
        "# Inverse transform\n",
        "train_predict = scaler.inverse_transform(train_predict)\n",
        "Y_train = scaler.inverse_transform([Y_train])\n",
        "test_predict = scaler.inverse_transform(test_predict)\n",
        "Y_test = scaler.inverse_transform([Y_test])\n",
        "\n",
        "# Calculate metrics\n",
        "train_rmse = np.sqrt(mean_squared_error(Y_train[0], train_predict[:,0]))\n",
        "test_rmse = np.sqrt(mean_squared_error(Y_test[0], test_predict[:,0]))\n",
        "train_mae = mean_absolute_error(Y_train[0], train_predict[:,0])\n",
        "test_mae = mean_absolute_error(Y_test[0], test_predict[:,0])"
      ],
      "metadata": {
        "id": "MDwbo7vi0ZG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f9baef-04ca-4ca4-9593-94bf6e397bec"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-1e742468caae>:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df = pd.read_csv('/content/1_Daily_minimum_temps.csv', parse_dates=['Date'], index_col='Date')\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0465 - val_loss: 0.0123\n",
            "Epoch 2/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0139 - val_loss: 0.0109\n",
            "Epoch 3/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0124 - val_loss: 0.0124\n",
            "Epoch 4/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0134 - val_loss: 0.0108\n",
            "Epoch 5/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0129 - val_loss: 0.0107\n",
            "Epoch 6/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0132 - val_loss: 0.0127\n",
            "Epoch 7/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0128 - val_loss: 0.0105\n",
            "Epoch 8/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0122 - val_loss: 0.0110\n",
            "Epoch 9/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0119 - val_loss: 0.0104\n",
            "Epoch 10/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0110 - val_loss: 0.0108\n",
            "Epoch 11/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0120 - val_loss: 0.0102\n",
            "Epoch 12/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0118 - val_loss: 0.0115\n",
            "Epoch 13/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0112 - val_loss: 0.0105\n",
            "Epoch 14/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0111 - val_loss: 0.0095\n",
            "Epoch 15/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0108 - val_loss: 0.0093\n",
            "Epoch 16/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0103 - val_loss: 0.0095\n",
            "Epoch 17/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0101 - val_loss: 0.0092\n",
            "Epoch 18/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0104 - val_loss: 0.0095\n",
            "Epoch 19/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0099\n",
            "Epoch 20/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0095\n",
            "Epoch 21/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.0094\n",
            "Epoch 22/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0092\n",
            "Epoch 23/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0102 - val_loss: 0.0096\n",
            "Epoch 24/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0105 - val_loss: 0.0092\n",
            "Epoch 25/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0100 - val_loss: 0.0091\n",
            "Epoch 26/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0100 - val_loss: 0.0096\n",
            "Epoch 27/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0096 - val_loss: 0.0091\n",
            "Epoch 28/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0091\n",
            "Epoch 29/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0091\n",
            "Epoch 30/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0101 - val_loss: 0.0093\n",
            "Epoch 31/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.0092\n",
            "Epoch 32/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.0095\n",
            "Epoch 33/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0099 - val_loss: 0.0096\n",
            "Epoch 34/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.0091\n",
            "Epoch 35/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0098 - val_loss: 0.0091\n",
            "Epoch 36/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0095 - val_loss: 0.0091\n",
            "Epoch 37/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0090 - val_loss: 0.0091\n",
            "Epoch 38/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0097 - val_loss: 0.0092\n",
            "Epoch 39/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0092\n",
            "Epoch 40/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0091\n",
            "Epoch 41/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0090\n",
            "Epoch 42/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0094 - val_loss: 0.0091\n",
            "Epoch 43/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0096 - val_loss: 0.0093\n",
            "Epoch 44/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0089 - val_loss: 0.0091\n",
            "Epoch 45/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0095 - val_loss: 0.0090\n",
            "Epoch 46/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.0091\n",
            "Epoch 47/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0093 - val_loss: 0.0093\n",
            "Epoch 48/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0091 - val_loss: 0.0091\n",
            "Epoch 49/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0090 - val_loss: 0.0091\n",
            "Epoch 50/50\n",
            "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0094 - val_loss: 0.0093\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Experiment 5.2: Sequence Text Prediction with LSTM\n",
        "\n",
        "Implementation Details\n",
        "For text generation, I used Shakespeare's sonnets from TensorFlow Datasets. The implementation shows a clear understanding of character-level text generation with LSTMs."
      ],
      "metadata": {
        "id": "UKPFdFir3hDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Load and preprocess text\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt',\n",
        "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Create mapping\n",
        "vocab = sorted(set(text))\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "idx2char = np.array(vocab)\n",
        "text_as_int = np.array([char2idx[c] for c in text])\n",
        "\n",
        "# Create training examples\n",
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Split input-target pairs\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "dataset = sequences.map(split_input_target)\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Model architecture\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size, embedding_dim), # Remove batch_input_shape\n",
        "        LSTM(rnn_units, return_sequences=True, stateful=True,\n",
        "             recurrent_initializer='glorot_uniform'),\n",
        "        Dropout(0.2),\n",
        "        LSTM(rnn_units, return_sequences=True, stateful=True,\n",
        "             recurrent_initializer='glorot_uniform'),\n",
        "        Dropout(0.2),\n",
        "        Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)\n",
        "\n",
        "# Custom callback for text generation during training\n",
        "def on_epoch_end(epoch, logs):\n",
        "    print(f'\\nGenerating text after epoch {epoch+1}')\n",
        "    start_string = \"ROMEO: \"\n",
        "    num_generate = 300\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "    temperature = 0.7\n",
        "\n",
        "    # Reset the states of the LSTM layers individually\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, LSTM):  # Check if the layer is an LSTM\n",
        "            layer.reset_states()\n",
        "\n",
        "    for i in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        # Reshape the predictions before squeezing\n",
        "        predictions = tf.reshape(predictions, (1, -1, vocab_size))\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    print(start_string + ''.join(text_generated))\n",
        "\n",
        "\n",
        "# Train model\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "history = model.fit(dataset, epochs=30, callbacks=[LambdaCallback(on_epoch_end=on_epoch_end)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAEAKVXm3gu1",
        "outputId": "dd711f55-2653-4fc8-aad6-5fcc8b8fa6ee"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - loss: 3.2280\n",
            "Generating text after epoch 1\n",
            "ROMEO: Iarlr, they and thee weame\n",
            "For hhan the machand efas by youd buncess\n",
            "Af wom le in by risas on and misher\n",
            "Mich thee and be heall to thepe goast,\n",
            "Fhe fortt dis no werins\n",
            "Le memang the lese and suw mears the otres so minn.\n",
            "\n",
            "BENCEI:\n",
            "N lot paxe word 're the thather we so of the gaens. Gerd the e hriss th\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 235ms/step - loss: 3.2257\n",
            "Epoch 2/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - loss: 2.1622\n",
            "Generating text after epoch 2\n",
            "ROMEO: Hor, my the heant unound I be night!\n",
            "\n",
            "DING EFARENT:\n",
            "I fay, my will the strant; to shall of lie dors are stall, is the his grome\n",
            "Till thou thou be agayselved be be a with pir,\n",
            "Mes your encesting in with this setter.\n",
            "\n",
            "HOSNENS:\n",
            "Hens what skeak of thyes in pleath the fonture?\n",
            "\n",
            "RUCHARCIO:\n",
            "Thy nest the re\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 258ms/step - loss: 2.1615\n",
            "Epoch 3/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.7907\n",
            "Generating text after epoch 3\n",
            "ROMEO: Pull it not.\n",
            "\n",
            "GROUCESTER:\n",
            "Hark me as he sir, that house bether Tall'd have men shall no marry\n",
            "To both my friends.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "Noth my man gime of mes, but in your\n",
            "best the being mer comes on meann,\n",
            "And were to my death\n",
            "His bried of all the personed\n",
            "And as breathed and must in the soil\n",
            "King let \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 236ms/step - loss: 1.7903\n",
            "Epoch 4/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.6000\n",
            "Generating text after epoch 4\n",
            "ROMEO: CORUEENTBERTHARD HIO:\n",
            "She brother with your love again, this was a frile; when thousandst thou come of the seach all my but to pray,\n",
            "That call thy perchs with state I wind their words thou\n",
            "hence to the little hand, that shall an is villain,\n",
            "Shall you to them, do that partain to her in the propessed \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - loss: 1.5999\n",
            "Epoch 5/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 1.4913\n",
            "Generating text after epoch 5\n",
            "ROMEO: Prart to him, the lightness there particle, send the very in your children proper sun,\n",
            "And make a sense and father state unto you,\n",
            "To the lack of the lessed in this rapes\n",
            "And must not one.\n",
            "\n",
            "PETRUCHIO:\n",
            "And made here to earth the goes of the marks\n",
            "To give me but at the motter which is the world,\n",
            "I kno\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 248ms/step - loss: 1.4913\n",
            "Epoch 6/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.4254\n",
            "Generating text after epoch 6\n",
            "ROMEO: Marria, sight it of his house,\n",
            "When it is bidded to change the moons of the rocks\n",
            "And with the time shall be a like too lady?\n",
            "Which strew'st thy brother comes the best curst about\n",
            "The city of your the lies in made a courterfeiter.\n",
            "\n",
            "DUKE EDWARD:\n",
            "How far thy fire enough, seed them the entreaty\n",
            "Which s\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - loss: 1.4254\n",
            "Epoch 7/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.3780\n",
            "Generating text after epoch 7\n",
            "ROMEO: An those good more is gone.\n",
            "\n",
            "BAPTISTA:\n",
            "Then give thee Varianter with the beast in the house,\n",
            "That thou hast not with a word is so are to my lusty,\n",
            "To be the very rest of my life's thoughts:\n",
            "But of a little of a strength to bid\n",
            "Here in the country, the state thou wilt be children of\n",
            "the subjects at m\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 244ms/step - loss: 1.3780\n",
            "Epoch 8/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - loss: 1.3325\n",
            "Generating text after epoch 8\n",
            "ROMEO: I\n",
            "do do not say our meature is,\n",
            "That children toad of his deed walls.\n",
            "\n",
            "BAPTISTA:\n",
            "I must see thee you, madam, and therefore I would shall be a treason\n",
            "When I to do the business, which I am.\n",
            "\n",
            "Servant:\n",
            "What is your worship will I go your prince,\n",
            "As within the world with them the teck of ote;\n",
            "For that w\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 234ms/step - loss: 1.3325\n",
            "Epoch 9/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.3002\n",
            "Generating text after epoch 9\n",
            "ROMEO: wime to be of thee?\n",
            "\n",
            "JULIET:\n",
            "I will not be to the base, she is mine own.\n",
            "\n",
            "BENVOLIO:\n",
            "A commould dangerous poar to know my life;\n",
            "And thou shalt slig at him for in the ghip\n",
            "As who not tears no doubtful person save\n",
            "Where shall I tribune to himself: the king contents\n",
            "Whose beauty grief the Tower.\n",
            "\n",
            "POMPEY\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 239ms/step - loss: 1.3002\n",
            "Epoch 10/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.2672\n",
            "Generating text after epoch 10\n",
            "ROMEO: I do be here;\n",
            "If you continue a thing is that in his\n",
            "face and old father; and therefore I require\n",
            "A shower of beauty the which we will have some single land and castle fall of day.\n",
            "\n",
            "KING RICHARD III:\n",
            "With me a telling day she be her suit,\n",
            "And like our cenerity expross the place.\n",
            "\n",
            "ROMEO:\n",
            "I know not o\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - loss: 1.2672\n",
            "Epoch 11/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 1.2337\n",
            "Generating text after epoch 11\n",
            "ROMEO: here is it not so?\n",
            "\n",
            "RICHARD:\n",
            "I like a life, as I come, to be of such a court\n",
            "As you dare nothing.\n",
            "\n",
            "First Citizen:\n",
            "When I do marry me, I pursue them all hearts\n",
            "Affliction of it. This has I honour'd him\n",
            "And this I will come on this faith groans much.\n",
            "\n",
            "GRUMIO:\n",
            "A good night! why stay she stabbed and pre\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - loss: 1.2338\n",
            "Epoch 12/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 1.2073\n",
            "Generating text after epoch 12\n",
            "ROMEO: we will have discreat. The fay of that, thou dost thou would\n",
            "Have been preserved with person to her sovereign,\n",
            "And with his hands to be thy death's before.\n",
            "\n",
            "PETRUCHIO:\n",
            "No, maidenously.\n",
            "\n",
            "ANTONIO:\n",
            "What means with her! Ha! what hast thou art love?\n",
            "\n",
            "BIONDELLO:\n",
            "My lord, the blood of country's body here,\n",
            "\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 237ms/step - loss: 1.2074\n",
            "Epoch 13/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - loss: 1.1794\n",
            "Generating text after epoch 13\n",
            "ROMEO: thou know'st not done.\n",
            "\n",
            "MENENIUS:\n",
            "No, no, a doubt, and be not villing you;\n",
            "To make me death, might love my country's sons.\n",
            "To stir and stoop and talk of still accused;\n",
            "Or that he did let me so, this is dare,\n",
            "When my love cousin what you are my father?\n",
            "Go, go, he hath a grieved in these tender in the\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 236ms/step - loss: 1.1794\n",
            "Epoch 14/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - loss: 1.1473\n",
            "Generating text after epoch 14\n",
            "ROMEO: Where are the compass\n",
            "That thou hast ask'd with the world will be free\n",
            "That we were rest and stay yet.\n",
            "\n",
            "PROSPERO:\n",
            "My lord, yet you were father with me:\n",
            "He seems to do at die.\n",
            "\n",
            "BRUTUS:\n",
            "Music at the sun of Clarence,\n",
            "The friend of the day,\n",
            "Though they do look upon his body to be bold,\n",
            "You know my fault\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 249ms/step - loss: 1.1473\n",
            "Epoch 15/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 1.1206\n",
            "Generating text after epoch 15\n",
            "ROMEO: no!\n",
            "I know the king is darkly, we were not the best.\n",
            "\n",
            "PETRUCHIO:\n",
            "Set them but a dream, and we are borned of colours:\n",
            "I do bare my officer and deserve to work.\n",
            "\n",
            "HORTENSIO:\n",
            "Then both your love as poison, to be gone.\n",
            "\n",
            "GREGORY:\n",
            "I will to my free words, the land of death.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "And so I speak \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 235ms/step - loss: 1.1207\n",
            "Epoch 16/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - loss: 1.0853\n",
            "Generating text after epoch 16\n",
            "ROMEO: God farewell.\n",
            "\n",
            "GREMIO:\n",
            "A strange distresset of the gentle wings\n",
            "And give you valiant sick and dried and breath\n",
            "To the pale very work, the king, as one,\n",
            "That often doing have not fall to be my state,\n",
            "If love my tale against the gods he stands.\n",
            "\n",
            "KATHARINA:\n",
            "I pray thee, now thy wife is not above a way.\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 244ms/step - loss: 1.0854\n",
            "Epoch 17/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 1.0568\n",
            "Generating text after epoch 17\n",
            "ROMEO: And am I lasted with my thunder-man, hearing\n",
            "her to the people, therefore discreet them against the king.\n",
            "\n",
            "SEBASTIAN:\n",
            "Ay, then have made them that which he could bear:\n",
            "I am in heaven here is the morning's eye,\n",
            "And sometimes many proud winds, many a witness\n",
            "That Romeo's dead, that lives to beg in't.\n",
            "\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 241ms/step - loss: 1.0569\n",
            "Epoch 18/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 1.0291\n",
            "Generating text after epoch 18\n",
            "ROMEO: a dangerous thimb,\n",
            "While I may renemperately your dinner.\n",
            "\n",
            "CLARENCE:\n",
            "How oft him on the sun I take the score\n",
            "And spit at thy consent to this doint them,\n",
            "As well as fair and earth so earth's true far from him.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "These first were terrived of a great designs.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "I thank you\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 244ms/step - loss: 1.0292\n",
            "Epoch 19/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - loss: 1.0005\n",
            "Generating text after epoch 19\n",
            "ROMEO: I will; 'tis like a county\n",
            "Prove as ever brother or enjoin a word:\n",
            "This fear, the hopeful mother, what with him?\n",
            "\n",
            "JOHN OF GAUNT:\n",
            "Well shows thee so that I will not be advenged.\n",
            "\n",
            "PETER:\n",
            "And thou too coast in basele and the rest,\n",
            "Upon my hands and rotten over him;\n",
            "And when the want of all my heart is \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 245ms/step - loss: 1.0006\n",
            "Epoch 20/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.9687\n",
            "Generating text after epoch 20\n",
            "ROMEO: good Camillo, what then in my breast,\n",
            "is he which needs must obey?\n",
            "\n",
            "BENVOLIO:\n",
            "For what deserves a whip of him?\n",
            "\n",
            "COMINIUS:\n",
            "Say you think?\n",
            "\n",
            "FLORIZEL:\n",
            "What with a hand of them?\n",
            "\n",
            "COMINIUS:\n",
            "Come, come, sir.\n",
            "\n",
            "PAULINA:\n",
            "How but a dishonord law and my son of mine, if you\n",
            "will give my leave and sound the man \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 240ms/step - loss: 0.9689\n",
            "Epoch 21/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.9409\n",
            "Generating text after epoch 21\n",
            "ROMEO: he would not be there before the latest day an eagle,\n",
            "And honour of his foneral threatening bed;\n",
            "But set the rebels find our brother Plantagenet,\n",
            "Make the to her lord.\n",
            "\n",
            "CORIOLANUS:\n",
            "You are a feast; and so we had the sun of mine.\n",
            "\n",
            "KING EDWARD IV:\n",
            "Then show his father hath been in the blood,\n",
            "The more \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 244ms/step - loss: 0.9410\n",
            "Epoch 22/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.9128\n",
            "Generating text after epoch 22\n",
            "ROMEO: we'll have no mourner to the sun,\n",
            "And fear the sin thou hast the dure of this\n",
            "To so and the moon out o' the consuls\n",
            "And lay me once in brothers to so.\n",
            "\n",
            "Provost:\n",
            "I may not live to my too: but I beseech you\n",
            "And you shall call me word.\n",
            "\n",
            "Provost:\n",
            "Here is the matter, then?\n",
            "\n",
            "POMPEY:\n",
            "I think she was worn t\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 244ms/step - loss: 0.9129\n",
            "Epoch 23/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - loss: 0.8848\n",
            "Generating text after epoch 23\n",
            "ROMEO: then go and horses! Come on;\n",
            "The law may be a thousand fortune in this alter.\n",
            "\n",
            "LUCENTIO:\n",
            "Here's Marcius, I cannot tell how I may sack his wife and victory.\n",
            "This is your worship's pleasure to assick\n",
            "A two deserved with my poor heart. So shall the rest will come.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "What stay are you sh\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 237ms/step - loss: 0.8849\n",
            "Epoch 24/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - loss: 0.8600\n",
            "Generating text after epoch 24\n",
            "ROMEO: Cominius, speak thou with thy speech.\n",
            "\n",
            "KING RICHARD III:\n",
            "Say, you never dead no farther feeling in\n",
            "the sea, the book of brats is not since a part\n",
            "And all protectors of their hearts together!\n",
            "Make proclaim my boots thee not to ruin,\n",
            "That ever will be taught by this deposed\n",
            "That I should kneel by this\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - loss: 0.8601\n",
            "Epoch 25/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - loss: 0.8356\n",
            "Generating text after epoch 25\n",
            "ROMEO: Prince of Wales, as friends, he souls!\n",
            "Who do himself, which stands not from their services she\n",
            "That you have made to part the oracle\n",
            "That you shall die for this for me to know\n",
            "That I am proud to bear.\n",
            "\n",
            "MENENIUS:\n",
            "Repent it with me, by your father's blood!\n",
            "\n",
            "QUEEN MARGARET:\n",
            "O mellows this, what with t\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 246ms/step - loss: 0.8357\n",
            "Epoch 26/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - loss: 0.8157\n",
            "Generating text after epoch 26\n",
            "ROMEO: then be it so?\n",
            "\n",
            "First Watchman:\n",
            "Why, how now, Edward? as thou slay this?\n",
            "\n",
            "LUCENTIO:\n",
            "Why, good my lord, I do not mind the truth.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "My lord, I would they were at Venice.\n",
            "\n",
            "First Murderer:\n",
            "We have all days since, gentle sir, the very more confess\n",
            "I cannot speak; then if this be done.\n",
            "\n",
            "ROM\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 238ms/step - loss: 0.8158\n",
            "Epoch 27/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - loss: 0.7913\n",
            "Generating text after epoch 27\n",
            "ROMEO: Somerset and tender dogs\n",
            "In that spoke but me at Caliban\n",
            "Whom not the duke, so or his life and honour,\n",
            "In haste that bled enough, with all expedition\n",
            "And order hath not been by any thing;\n",
            "And so had you betray me; but it be done,\n",
            "To cross me to his country's brother by?\n",
            "What from the dead blows then\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 243ms/step - loss: 0.7914\n",
            "Epoch 28/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - loss: 0.7726\n",
            "Generating text after epoch 28\n",
            "ROMEO: go, sir; and so, farewell.\n",
            "I have been faction, sir, and so have seen so change\n",
            "Like to a man's person, and your husband's drums.\n",
            "\n",
            "VOLUMNIA:\n",
            "Men he should be advised. Yet I was the humour person, you have shown\n",
            "For such a paragon to the ground they see,\n",
            "The other did believe two match is come:\n",
            "The v\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 229ms/step - loss: 0.7727\n",
            "Epoch 29/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - loss: 0.7534\n",
            "Generating text after epoch 29\n",
            "ROMEO: come, sir.\n",
            "\n",
            "POLIXENES:\n",
            "What would you do? \n",
            "MERCUTIO:\n",
            "I have deserved nobly.\n",
            "\n",
            "First Citizen:\n",
            "We have been disloyance, you were not the water of the blood\n",
            "Of present days in my desires news,\n",
            "While we comes, as in age,\n",
            "That in the street discomfort of his supher,\n",
            "A happy and a holy dry intent.\n",
            "\n",
            "PRINCE \n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 235ms/step - loss: 0.7535\n",
            "Epoch 30/30\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - loss: 0.7343\n",
            "Generating text after epoch 30\n",
            "ROMEO: on his fault, I must confess;\n",
            "And when I say, I speak not so much strength\n",
            "As if the world give sees and set off their summer wealths;\n",
            "And that is more than misery.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "That in this cause as big as a poor gentleman, and a\n",
            "lovering tear; the mayor in the midst of this state,\n",
            "Which the re\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 234ms/step - loss: 0.7344\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Experiment 5.3: Text Classification with LSTM\n",
        "Implementation Details\n",
        "For text classification, I implemented an LSTM model for sentiment analysis using the IMDB movie reviews dataset. The code demonstrates expertise in sequence classification tasks."
      ],
      "metadata": {
        "id": "IoFzZEd53pTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bidirectional LSTM architecture proved particularly effective for sentiment analysis, capturing both forward and backward contextual relationships in the text. The dropout layers (0.5) helped prevent overfitting despite the model's capacity."
      ],
      "metadata": {
        "id": "kvkRvXXU3x_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Load and preprocess data\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 64\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "# Model architecture\n",
        "def build_classifier():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Bidirectional(LSTM(32)))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_classifier()\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=15,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.savefig('confusion_matrix.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "o3bJr2jA3tzy",
        "outputId": "8c1a534a-18e1-48a9-9198-0b2aba343ea8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "Epoch 1/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 83ms/step - accuracy: 0.6672 - loss: 0.5810 - val_accuracy: 0.8322 - val_loss: 0.3857\n",
            "Epoch 2/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 81ms/step - accuracy: 0.8808 - loss: 0.3072 - val_accuracy: 0.8670 - val_loss: 0.3219\n",
            "Epoch 3/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 79ms/step - accuracy: 0.9216 - loss: 0.2149 - val_accuracy: 0.8688 - val_loss: 0.3296\n",
            "Epoch 4/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 75ms/step - accuracy: 0.9566 - loss: 0.1327 - val_accuracy: 0.8666 - val_loss: 0.3586\n",
            "Epoch 5/15\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 73ms/step - accuracy: 0.9702 - loss: 0.0967 - val_accuracy: 0.8472 - val_loss: 0.4126\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.81      0.84     12500\n",
            "           1       0.82      0.89      0.85     12500\n",
            "\n",
            "    accuracy                           0.85     25000\n",
            "   macro avg       0.85      0.85      0.85     25000\n",
            "weighted avg       0.85      0.85      0.85     25000\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}